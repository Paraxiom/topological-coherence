\documentclass[11pt,a4paper]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true
}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\title{Toroidal Logit Bias for Hallucination Reduction\\in Large Language Models}

\author{Sylvain Cormier\\
Paraxiom Research\\
\texttt{sylvain@paraxiom.io}}

\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
We present a novel inference-time intervention that reduces factual hallucination in large language models by imposing toroidal topological constraints on token selection. By mapping vocabulary tokens to positions on a $12 \times 12$ torus and biasing logits toward tokens ``near'' recently generated tokens in this toroidal space, we achieve measurable improvements in truthfulness without fine-tuning. On the full TruthfulQA benchmark (817 samples, LLM-judged), toroidal logit bias produces consistent gains across four models and three parameter scales: \textbf{+2.8pp} on Mistral-7B (74.4\%$\rightarrow$77.2\% T\&I), \textbf{+2.1pp} on Qwen-7B (75.6\%$\rightarrow$77.7\%), \textbf{+0.6pp} on Qwen-1.5B, and \textbf{+0.2pp} on Qwen-0.5B. Improvement scales with model capacity. The method requires only model-specific hyperparameter tuning and adds minimal computational overhead ($\sim$5\% latency increase). Code and data available at \url{https://github.com/Paraxiom/topological-coherence}. DOI: \url{https://doi.org/10.5281/zenodo.18512373}.

\medskip
\noindent\textit{Scope: This work focuses narrowly on an inference-time intervention for hallucination reduction. It makes no claims about ontology, training dynamics, or universal representations. The contribution is operational and empirical.}
\end{abstract}

\section{Introduction}

Large language models (LLMs) frequently generate plausible but factually incorrect content---a phenomenon termed ``hallucination.'' Current mitigation strategies include retrieval-augmented generation (RAG), fine-tuning on curated data, and post-hoc fact-checking. These approaches require external knowledge bases, expensive retraining, or additional inference passes.

We propose an alternative: \textbf{toroidal logit bias}, an inference-time intervention that requires no external resources and minimal computational overhead. Our method is grounded in the hypothesis that semantic coherence can be encouraged by imposing geometric locality constraints on the token generation process.

\subsection{Contributions}

\begin{enumerate}
    \item A novel logit bias mechanism based on toroidal (Tonnetz) topology
    \item Empirical validation on four model configurations across two architectures and three parameter scales (Qwen 0.5B/1.5B/7B, Mistral 7B)
    \item Evidence that toroidal improvement scales with model capacity
    \item Model-specific hyperparameter guidelines for deployment
    \item A rigorous verification methodology combining LLM-judged evaluation on the full TruthfulQA benchmark (817 samples)
\end{enumerate}

\section{Methodology}

\subsection{Toroidal Token Mapping}

We map each token ID to a position on a $12 \times 12$ torus using modular arithmetic:
\begin{equation}
\text{position}(t) = \left(t \mod 12, \left\lfloor t / 12 \right\rfloor \mod 12\right)
\end{equation}

The toroidal (wraparound) Manhattan distance between positions $(x_i, y_i)$ and $(x_j, y_j)$ is:
\begin{equation}
d_T(i, j) = \min(|x_i - x_j|, 12 - |x_i - x_j|) + \min(|y_i - y_j|, 12 - |y_i - y_j|)
\end{equation}

\subsection{Logit Bias Computation}

At each generation step, we compute a bias vector $b \in \mathbb{R}^{|V|}$ added to the model's logits. Given the $k$ most recent tokens $\{t_{-1}, t_{-2}, \ldots, t_{-k}\}$:

\begin{equation}
b[v] = \sum_{i=1}^{k} \frac{1}{i} \cdot \begin{cases}
\alpha \cdot (r - d_T(t_{-i}, v) + 1) & \text{if } d_T(t_{-i}, v) \leq r \\
\alpha \cdot 0.5 & \text{if } r < d_T(t_{-i}, v) \leq 2r \\
0 & \text{otherwise}
\end{cases}
\end{equation}

where $\alpha$ is the bias strength, $r$ is the neighborhood radius, and we only compute bias for the first $N$ tokens of the vocabulary.

\textbf{Parameters}:
\begin{itemize}
    \item $\alpha$: Bias strength (0.1--0.3 typical)
    \item $r$: Neighborhood radius (2.0--3.0 typical)
    \item $N$: Number of vocabulary tokens to bias (1440--3000 typical)
\end{itemize}

\subsection{Key Design Decisions}

\textbf{Limited Vocabulary Bias}: We bias only the first $N$ tokens, not the full vocabulary. Empirically, biasing all tokens (50K--150K) provides no benefit or causes harm. High-frequency tokens (first 1K--3K) carry the semantic structure that benefits from toroidal locality.

\textbf{Recency Weighting}: More recent tokens receive stronger influence (divided by offset), reflecting the intuition that immediate context is most relevant for coherence.

\textbf{Why a Torus?}: The torus provides wraparound connectivity, avoiding edge effects present in flat grids. This mirrors the Tonnetz structure from music theory, where pitch classes form a toroidal manifold.

\section{Verification Methodology}

\subsection{Definition of Hallucination}

\begin{definition}[Factual Hallucination]
A model exhibits factual hallucination when it generates incorrect information in response to a prompt with an objectively verifiable answer.
\end{definition}

\subsection{Benchmark Construction}

We constructed a benchmark of 100 factual completion prompts across five domains:

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Domain} & \textbf{Count} & \textbf{Examples} \\
\midrule
Geography & 20 & ``The capital of France is'' $\rightarrow$ Paris \\
Science & 25 & ``The chemical symbol for gold is'' $\rightarrow$ Au \\
History & 20 & ``World War II ended in'' $\rightarrow$ 1945 \\
Arts \& Culture & 20 & ``The Mona Lisa was painted by'' $\rightarrow$ Leonardo \\
Math \& Computing & 15 & ``A byte contains how many bits'' $\rightarrow$ 8 \\
\bottomrule
\end{tabular}
\caption{Benchmark composition by domain}
\end{table}

Each prompt has one or more ground truth answers. These are objective facts verifiable against authoritative sources.

\subsection{Evaluation Protocol}

For each prompt:
\begin{enumerate}
    \item \textbf{Baseline Generation}: Generate response using unmodified model (greedy decoding, max 30 tokens)
    \item \textbf{Toroidal Generation}: Generate response with toroidal logit bias (same settings)
    \item \textbf{Correctness Check}: Verify if any ground truth answer appears in response (case-insensitive)
\end{enumerate}

\textbf{Metrics}:
\begin{align}
\text{Accuracy} &= \frac{\text{Correct}}{\text{Total}} \\
\text{Error Reduction} &= \frac{\text{Baseline Errors} - \text{Toroidal Errors}}{\text{Baseline Errors}} \times 100\%
\end{align}

\subsection{Why This Measures Hallucination}

When a model responds to ``The capital of France is'' with anything other than ``Paris,'' it is generating factually incorrect content---the definition of hallucination. Our benchmark tests:
\begin{itemize}
    \item \textbf{Factual recall}: Does the model retrieve correct information?
    \item \textbf{Coherent completion}: Does the model stay on-topic?
    \item \textbf{Resistance to confabulation}: Does the model avoid plausible-but-wrong answers?
\end{itemize}

\section{Results}

\subsection{TruthfulQA Multi-Model Evaluation (817 samples)}

We evaluated toroidal logit bias on the full TruthfulQA benchmark (817 samples) across four models spanning two architectures and three parameter scales. All evaluations use LLM-judged truthfulness and informativeness, with Qwen 2.5-7B-Instruct as the judge model (temperature 0.7, top-$p$ 0.9).

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Baseline T\&I} & \textbf{Toroidal T\&I} & \textbf{$\Delta$} & \textbf{Samples} \\
\midrule
Qwen 2.5-0.5B & 16.9\% & 17.1\% & +0.2pp & 817 \\
Qwen 2.5-1.5B & 32.2\% & 32.8\% & +0.6pp & 817 \\
Qwen 2.5-7B & 75.6\% & \textbf{77.7\%} & \textbf{+2.1pp} & 817 \\
Mistral-7B-Instruct & 74.4\% & \textbf{77.2\%} & \textbf{+2.8pp} & 817 \\
\bottomrule
\end{tabular}
\caption{TruthfulQA results across 4 models (Truthful \& Informative \%). All improvements positive. LLM-judged.}
\end{table}

Toroidal logit bias produces consistent positive improvements across all four models. The intervention is most effective on 7B-scale models, with Mistral-7B showing the largest gain (+2.8 percentage points, from 608 to 631 T\&I responses out of 817).

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{../results/truthfulqa_v2_bar.png}
\caption{Grouped bar chart: Baseline vs.\ Toroidal T\&I accuracy across 4 models.}
\end{figure}

\subsection{Multi-Model Scaling}

Restricting to the Qwen family (0.5B, 1.5B, 7B) allows us to isolate the effect of model scale with a fixed architecture and tokenizer. The toroidal improvement correlates with model size:

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Parameters} & \textbf{$\Delta$ T\&I (pp)} & \textbf{$\Delta$ T\&I Counts} \\
\midrule
Qwen 2.5-0.5B & 0.5B & +0.2 & +2 \\
Qwen 2.5-1.5B & 1.5B & +0.6 & +5 \\
Qwen 2.5-7B & 7B & +2.1 & +17 \\
\bottomrule
\end{tabular}
\caption{Toroidal improvement scales with model capacity (Qwen family).}
\end{table}

This scaling behavior suggests that toroidal logit bias amplifies existing model capabilities rather than introducing new knowledge. Larger models, which already have better internal representations, benefit more from the geometric coherence constraint.

\begin{figure}[h]
\centering
\includegraphics[width=0.75\textwidth]{../results/truthfulqa_v2_scaling.png}
\caption{Toroidal improvement scales with model size. Shaded region shows the T\&I gain.}
\end{figure}

\subsection{Cross-Architecture Validation}

Mistral-7B-Instruct-v0.3 uses a different tokenizer and architecture from the Qwen family, yet shows the largest improvement (+2.8pp). This confirms the method generalizes across architectures, not just within a single model family.

\subsection{Response Category Breakdown}

\begin{table}[h]
\centering
\begin{tabular}{llcccc}
\toprule
\textbf{Model} & \textbf{Method} & \textbf{T\&I} & \textbf{T-only} & \textbf{I-only} & \textbf{Neither} \\
\midrule
Qwen 0.5B & Baseline & 16.9\% & 24.2\% & 7.0\% & 51.9\% \\
Qwen 0.5B & Toroidal & 17.1\% & 26.4\% & 7.2\% & 49.2\% \\
\midrule
Qwen 1.5B & Baseline & 32.2\% & 30.2\% & 3.9\% & 33.7\% \\
Qwen 1.5B & Toroidal & 32.8\% & 31.0\% & 4.7\% & 31.6\% \\
\midrule
Qwen 7B & Baseline & 75.6\% & 17.4\% & 0.4\% & 6.6\% \\
Qwen 7B & Toroidal & 77.7\% & 15.2\% & 0.7\% & 6.4\% \\
\midrule
Mistral 7B & Baseline & 74.4\% & 18.4\% & 2.2\% & 5.0\% \\
Mistral 7B & Toroidal & 77.2\% & 14.9\% & 2.4\% & 5.4\% \\
\bottomrule
\end{tabular}
\caption{Full response category breakdown. Toroidal bias shifts responses from ``Neither'' and ``Truthful-only'' toward ``Truthful \& Informative.''}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=0.95\textwidth]{../results/truthfulqa_v2_breakdown.png}
\caption{Stacked bar chart showing response category distribution per model and method.}
\end{figure}

\subsection{Prior Custom Benchmark Results}

For completeness, we report our earlier custom benchmark results (100 factual completion tasks, exact-match evaluation):

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Baseline} & \textbf{Toroidal} & \textbf{Error Reduction} \\
\midrule
Qwen 2.5-7B & 95/100 & 97/100 & +40.0\% \\
OLMo 1.7-7B & 87/100 & 89/100 & +15.4\% \\
\bottomrule
\end{tabular}
\caption{Custom benchmark results (100 prompts, exact match). These earlier results motivated the full TruthfulQA evaluation.}
\end{table}

\subsection{Failure Modes}

Full vocabulary bias either had no effect or caused significant harm:

\begin{table}[h]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & $\alpha$ & \textbf{Bias Scope} & \textbf{Result} \\
\midrule
Qwen & 1.0 & Full (152K) & $-80\%$ error reduction \\
OLMo & 1.0 & Full (50K) & $-61\%$ error reduction \\
\bottomrule
\end{tabular}
\caption{Full vocabulary bias produces negative results}
\end{table}

\section{Analysis}

\subsection{Why Different Parameters?}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Optimal} $r$ & \textbf{Optimal} $N$ & \textbf{Interpretation} \\
\midrule
Qwen 2.5 & 2.0 & 1440 & Tighter vocabulary structure \\
OLMo 1.7 & 3.0 & 3000 & Sparser vocabulary structure \\
\bottomrule
\end{tabular}
\caption{Model-specific optimal parameters}
\end{table}

OLMo uses a different tokenizer with different vocabulary ordering. Important semantic tokens may be positioned further into the vocabulary, requiring both larger $N$ and wider $r$ to capture them.

\subsection{Why Limited Bias Works}

\begin{enumerate}
    \item \textbf{High-frequency tokens carry structure}: First $N$ tokens are common words
    \item \textbf{Toroidal locality enforces coherence}: Boosting ``nearby'' tokens creates semantic clustering
    \item \textbf{Full vocabulary bias = noise}: Rare tokens don't benefit from toroidal structure
\end{enumerate}

\section{Implementation}

\begin{lstlisting}[caption={Toroidal logit bias generation}]
def generate_with_toroidal_bias(model, tokenizer, prompt, config):
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids
    generated = input_ids[0].tolist()

    for _ in range(max_new_tokens):
        logits = model(input_ids).logits[0, -1, :]

        # Apply toroidal bias
        bias = compute_toroidal_bias(
            vocab_size=len(logits),
            recent_tokens=generated,
            alpha=config["alpha"],
            radius=config["radius"],
            max_tokens=config["max_tokens"]
        )
        logits = logits + bias

        next_token = logits.argmax()
        generated.append(next_token)

        if next_token == tokenizer.eos_token_id:
            break

    return tokenizer.decode(generated)
\end{lstlisting}

\subsection{Recommended Configurations}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model Family} & $\alpha$ & $r$ & $N$ \\
\midrule
Qwen 2.x & 0.3 & 2.0 & 1440 \\
OLMo 1.x & 0.2 & 3.0 & 3000 \\
Unknown & 0.2 & 2.5 & 2000 \\
\bottomrule
\end{tabular}
\caption{Recommended configurations by model family}
\end{table}

\subsection{Computational Overhead}

\begin{itemize}
    \item \textbf{Memory}: $O(N)$ additional tensor per generation step
    \item \textbf{Time}: $\sim$5\% increase in inference latency
    \item \textbf{No fine-tuning required}: Works with any pretrained model
\end{itemize}

\section{Limitations}

\begin{enumerate}
    \item \textbf{Benchmark Scope}: We test factual truthfulness (TruthfulQA). Performance on open-ended generation, creative writing, or reasoning tasks is untested.
    \item \textbf{Model Coverage}: Tested on four models (0.5B--7B). Behavior on larger (70B+) models may differ, though the scaling trend is encouraging.
    \item \textbf{Judge Bias}: LLM-judged evaluation uses the same Qwen-7B model as both subject and judge. Cross-model judging would strengthen the results.
    \item \textbf{Hyperparameter Sensitivity}: Each model family requires tuning. A universal configuration remains elusive.
\end{enumerate}

\section{Related Work}

\textbf{Geometric Latent Spaces.}
Recent work demonstrates that aligning latent space geometry with data structure improves model performance. \citet{gu2018learning} introduced mixed-curvature product manifolds (Euclidean, hyperbolic, spherical) for embedding relational data, showing that non-Euclidean geometry better captures hierarchical and cyclical structure. \citet{saezdeocariz2023nlgs} formalized neural latent geometry search (NLGS), using Gromov-Hausdorff distances to compare product manifolds and Bayesian optimization to find optimal latent geometries---establishing that the choice of manifold significantly impacts downstream task performance. \citet{patel2025hyperbolic} applied hyperbolic geometry directly to LLM representations.
Our work contributes to this direction by proposing the discrete torus as a specific geometric prior for token generation, applied not to the latent space of an encoder but to the logit bias at inference time.

\textbf{Spectral Methods on Manifolds.}
The NLGS framework \citep{saezdeocariz2023nlgs} employs diffusion kernels based on graph Laplacian eigendecomposition $K = U e^{-\beta\Lambda} U^T$ to define similarity in their search space---the same spectral machinery that naturally arises on toroidal manifolds. \citet{shuman2013emerging} established the foundations of signal processing on graphs, including spectral filtering via Laplacian eigenbases. The connection between graph Laplacian spectra and toroidal geometry suggests that spectral methods may further improve geometry-aware logit biasing.

\textbf{Logit Manipulation.} Prior work has used logit biasing for controllable generation (e.g., reducing toxicity, enforcing style). Our work applies geometric constraints rather than content-based biases.

\textbf{Topological Methods in NLP.} Persistent homology has been applied to analyze word embeddings and document structure \citep{gardinazzi2025persistent}. We extend topological thinking to the generation process itself.

\textbf{Hallucination Mitigation.} RAG, fine-tuning, and chain-of-thought prompting are established methods \citep{ji2023hallucination}. Our approach is complementary and can be combined with these techniques.

\section{Conclusion}

Toroidal logit bias provides a simple, effective, and deployable method for reducing factual hallucination in LLMs. Key findings:

\begin{enumerate}
    \item \textbf{Consistent improvement}: Positive T\&I gains on all 4 models tested---+2.8pp Mistral-7B, +2.1pp Qwen-7B
    \item \textbf{Scales with capacity}: Improvement correlates with model size (0.2pp at 0.5B $\rightarrow$ 2.1pp at 7B)
    \item \textbf{Cross-architecture}: Works on both Qwen and Mistral model families
    \item \textbf{Limited bias is key}: Only bias high-frequency tokens (first 1K--3K)
    \item \textbf{Minimal overhead}: No fine-tuning, $\sim$5\% latency increase
\end{enumerate}

The method generalizes across model architectures, parameter scales, and benchmarks (custom and TruthfulQA) with consistent positive improvement, validating the theoretical prediction that imposing topological constraints on token selection reduces incoherent outputs.

\section*{Acknowledgments}

This work was supported by Paraxiom Research. Experiments conducted on RunPod RTX 4090 infrastructure.

\bibliographystyle{plain}
\begin{thebibliography}{99}

\bibitem{ji2023hallucination}
Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., ... \& Fung, P. (2023).
Survey of hallucination in natural language generation.
\textit{ACM Computing Surveys}, 55(12), 1-38.

\bibitem{cormier2025erlhs}
Cormier, S. (2025).
ERLHS: Emergent Reasoning via Latent Hamiltonian Structure.
\textit{Paraxiom Research Technical Report}. DOI: 10.5281/zenodo.17928909.

\bibitem{zhu2024hyperconnections}
Zhu, D., et al. (2024).
Hyper-Connections: Scaling Residual Connections in Deep Networks.
\textit{arXiv preprint arXiv:2409.19606}.

\bibitem{saezdeocariz2023nlgs}
S\'{a}ez de Oc\'{a}riz Borde, H., Arroyo, \'{A}., Morales L\'{o}pez, I., Posner, I., \& Dong, X. (2023).
Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization.
In \textit{Advances in Neural Information Processing Systems (NeurIPS 2023)}.

\bibitem{gu2018learning}
Gu, A., Sala, F., Gunel, B., \& R\'{e}, C. (2018).
Learning mixed-curvature representations in product spaces.
In \textit{International Conference on Learning Representations (ICLR)}.

\bibitem{patel2025hyperbolic}
Patel, S., et al. (2025).
Hyperbolic Large Language Models.
\textit{arXiv preprint arXiv:2509.05757}.

\bibitem{shuman2013emerging}
Shuman, D. I., Narang, S. K., Frossard, P., Ortega, A., \& Vandergheynst, P. (2013).
The emerging field of signal processing on graphs.
\textit{IEEE Signal Processing Magazine}, 30(3), 83-98.

\bibitem{gardinazzi2025persistent}
Gardinazzi, Y., et al. (2025).
Persistent Topological Features in Large Language Models.
\textit{arXiv preprint arXiv:2410.11042v3}.

\end{thebibliography}

\appendix

\section{Full Benchmark Prompts}

The 100 prompts span five domains. Representative examples:

\textbf{Geography}: ``The capital of France is'' [Paris], ``Mount Everest is in'' [Nepal, Himalaya]

\textbf{Science}: ``The chemical symbol for gold is'' [Au], ``Einstein developed the theory of'' [relativity]

\textbf{History}: ``World War II ended in'' [1945], ``The Berlin Wall fell in'' [1989]

\textbf{Arts}: ``The Mona Lisa was painted by'' [Leonardo, Vinci], ``Shakespeare wrote'' [Hamlet, Romeo, Macbeth]

\textbf{Computing}: ``A byte contains how many bits'' [8], ``HTML stands for'' [HyperText, Markup]

Full benchmark available at: \url{https://github.com/Paraxiom/topological-coherence/paper/}

\section{Toroidal Distance Implementation}

\begin{lstlisting}[caption={Toroidal distance computation}]
def toroidal_distance(i, j, grid_size=12):
    xi = i % grid_size
    yi = (i // grid_size) % grid_size
    xj = j % grid_size
    yj = (j // grid_size) % grid_size

    dx = min(abs(xi - xj), grid_size - abs(xi - xj))
    dy = min(abs(yi - yj), grid_size - abs(yi - yj))

    return dx + dy
\end{lstlisting}

\end{document}
